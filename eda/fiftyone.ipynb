{"cells": [{"cell_type": "code", "execution_count": null, "id": "5a335a90", "metadata": {}, "outputs": [], "source": ["import fiftyone as fo\n", "import pandas as pd\n", "import numpy as np\n", "import cv2, json, os, glob, re\n", "from tqdm import tqdm\n", "\n", "BASE_DIR = \"/data/ephemeral/home/data\"\n", "TRAIN_IMG_ROOT = \"/data/ephemeral/home/data/train/DCM\"\n", "TRAIN_LBL_ROOT = \"/data/ephemeral/home/data/train/outputs_json\"\n", "TEST_IMG_ROOT = \"/data/ephemeral/home/data/test/DCM\"\n", "META_PATH = \"/data/ephemeral/home/data/meta_data.xlsx\"\n", "\n", "DATASET_NAME = \"Hand Bone Image Segmentation\""]}, {"cell_type": "code", "execution_count": null, "id": "7b4f0b56", "metadata": {}, "outputs": [], "source": ["def get_cleaned_meta(path) :\n", "    df = pd.read_excel(path)\n", "    # 1. \ubd88\ud544\uc694\ud55c 'Unnamed' \uceec\ub7fc \uc81c\uac70\n", "    df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n", "\n", "    # 2. \uc131\ubcc4: \ud2b9\uc218\ubb38\uc790 \uc81c\uac70\n", "    if '\uc131\ubcc4' in df.columns:\n", "        df['\uc131\ubcc4'] = df['\uc131\ubcc4'].astype(str).str.extract(r'([\uac00-\ud7a3]+)')[0].str.strip()\n", "    \n", "    # 3. ID: \uc815\uc218\ud615(int) \ubcc0\ud658\n", "    if 'ID' in df.columns:\n", "        df['ID'] = pd.to_numeric(df['ID'], errors='coerce').fillna(0).astype(int)\n", "\n", "    # 4. \ud0a4/\ubab8\ubb34\uac8c: \uc2e4\uc218\ud615(float) \ubcc0\ud658 (\uc18c\uc218\uc810 \uc720\uc9c0)\n", "    # \uc22b\uc790\uac00 \uc544\ub2cc \uac12\uc774 \uc788\uc73c\uba74 NaN(\uacb0\uce21\uce58)\uc73c\ub85c \ucc98\ub9ac\ub429\ub2c8\ub2e4.\n", "    if '\ud0a4(\uc2e0\uc7a5)' in df.columns:\n", "        df['\ud0a4(\uc2e0\uc7a5)'] = pd.to_numeric(df['\ud0a4(\uc2e0\uc7a5)'], errors='coerce').astype(float)\n", "    if '\uccb4\uc911(\ubab8\ubb34\uac8c)' in df.columns:\n", "        df['\uccb4\uc911(\ubab8\ubb34\uac8c)'] = pd.to_numeric(df['\uccb4\uc911(\ubab8\ubb34\uac8c)'], errors='coerce').astype(float)\n", "        \n", "    return df\n", "\n", "df_meta = get_cleaned_meta(META_PATH)\n", "print(f\"Metadata loaded: {len(df_meta)} rows\")\n", "display(df_meta.head())"]}, {"cell_type": "code", "execution_count": null, "id": "b02f91a2", "metadata": {}, "outputs": [], "source": ["if DATASET_NAME in fo.list_datasets():\n", "    fo.delete_dataset(DATASET_NAME)\n", "\n", "dataset = fo.Dataset(DATASET_NAME)\n", "samples = []\n", "\n", "# --- 1. Train \ub370\uc774\ud130 \ucd94\uac00 ---\n", "json_paths = glob.glob(os.path.join(TRAIN_LBL_ROOT, \"**/*.json\"), recursive=True)\n", "for j_path in tqdm(json_paths, desc=\"Adding Train Samples\"):\n", "    folder_name = os.path.basename(os.path.dirname(j_path))\n", "    f_id = int(''.join(filter(str.isdigit, folder_name)))\n", "    \n", "    # \uc774\ubbf8\uc9c0 \uacbd\ub85c \ub9e4\uce6d (outputs_json -> DCM)\n", "    img_path = j_path.replace('.json', '.png').replace('outputs_json', 'DCM')\n", "    if not os.path.exists(img_path): continue\n", "    \n", "    sample = fo.Sample(filepath=img_path, tags=[\"train\"])\n", "    sample[\"ID\"] = f_id\n", "    \n", "    # \uba54\ud0c0\ub370\uc774\ud130 \uc8fc\uc785 (\uc18d\uc131\uba85: ID, \ub098\uc774, \uc131\ubcc4, \uccb4\uc911, \ud0a4)\n", "    meta_row = df_meta[df_meta['ID'] == f_id]\n", "    if not meta_row.empty:\n", "        row = meta_row.iloc[0]\n", "        sample[\"Gender\"] = row['\uc131\ubcc4']\n", "        sample[\"Age\"] = row['\ub098\uc774']\n", "        sample[\"Weight\"] = row['\uccb4\uc911(\ubab8\ubb34\uac8c)']\n", "        sample[\"Height\"] = row['\ud0a4(\uc2e0\uc7a5)']\n", "    \n", "    samples.append(sample)\n", "\n", "# --- 2. Test \ub370\uc774\ud130 \ucd94\uac00 (\ub77c\ubca8\uc740 \uc5c6\uc9c0\ub9cc \uba54\ud0c0\ub370\uc774\ud130\ub294 \uc5f0\uacb0) ---\n", "test_pngs = glob.glob(os.path.join(TEST_IMG_ROOT, \"**/*.png\"), recursive=True)\n", "for t_path in tqdm(test_pngs, desc=\"Adding Test Samples\"):\n", "    folder_name = os.path.basename(os.path.dirname(t_path))\n", "    f_id = int(''.join(filter(str.isdigit, folder_name)))\n", "    \n", "    sample = fo.Sample(filepath=t_path, tags=[\"test\"])\n", "    sample[\"ID\"] = f_id\n", "    \n", "    meta_row = df_meta[df_meta['ID'] == f_id]\n", "    if not meta_row.empty:\n", "        row = meta_row.iloc[0]\n", "        sample[\"Gender\"] = row['\uc131\ubcc4']\n", "        sample[\"Age\"] = row['\ub098\uc774']\n", "        sample[\"Weight\"] = row['\uccb4\uc911(\ubab8\ubb34\uac8c)']\n", "        sample[\"Height\"] = row['\ud0a4(\uc2e0\uc7a5)']\n", "    \n", "    samples.append(sample)\n", "\n", "dataset.add_samples(samples)\n", "dataset.persistent = True\n", "print(f\"Created dataset '{DATASET_NAME}' with {len(dataset)} samples.\")"]}, {"cell_type": "code", "execution_count": null, "id": "f0a0b7f5", "metadata": {}, "outputs": [], "source": ["with dataset.save_context() as context:\n", "    # 1. Train \ub370\uc774\ud130\uc758 Ground Truth \uc5c5\ub370\uc774\ud2b8\n", "    for sample in tqdm(dataset.match_tags(\"train\"), desc=\"Updating GT\"):\n", "        json_path = sample.filepath.replace('.png', '.json').replace('DCM', 'outputs_json')\n", "        \n", "        if os.path.exists(json_path):\n", "            with open(json_path, 'r') as f:\n", "                ann_data = json.load(f)\n", "            \n", "            # \uc774\ubbf8\uc9c0 \uc0ac\uc774\uc988 \uac00\uc838\uc624\uae30 (\uc815\uaddc\ud654\uc6a9)\n", "            img = cv2.imread(sample.filepath)\n", "            h, w = img.shape[:2]\n", "            \n", "            polylines = []\n", "            for ann in ann_data.get('annotations', []):\n", "                pts = ann.get('points', [])\n", "                norm_pts = [[(p[0]/w, p[1]/h) for p in pts]]\n", "                polylines.append(fo.Polyline(label=ann['label'], points=norm_pts, closed=True, filled=True))\n", "            \n", "            sample[\"ground_truth\"] = fo.Polylines(polylines=polylines)\n", "        \n", "        context.save(sample)\n", "\n", "print(\"Update Complete!\")"]}, {"cell_type": "code", "execution_count": null, "id": "17542853", "metadata": {}, "outputs": [], "source": ["# \uc608\uce21 \uacb0\uacfc \ud655\uc778\ud558\uace0 \uc2f6\uc73c\uba74 \uc8fc\uc11d\ud574\uc81c \ud6c4 CSV_PATH\uc5d0 csv \uacbd\ub85c \uc785\ub825\ud574\uc8fc\uc138\uc694.\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import cv2\n", "import os\n", "import fiftyone as fo\n", "from tqdm import tqdm\n", "\n", "# 1. CSV \ud30c\uc77c \ub85c\ub4dc\n", "CSV_PATH = \"/data/ephemeral/home/csb/ss/test_submission_CSB_011_segb3_4del.csv\" # \ud83c\udf4e \uc2dc\uac01\ud654 \uc6d0\ud558\ub294 csv \ud30c\uc77c \uacbd\ub85c \uc785\ub825\n", "if not os.path.exists(CSV_PATH):\n", "    print(f\"\u26a0\ufe0f {CSV_PATH} \ud30c\uc77c\uc744 \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\")\n", "else:\n", "    pred_df = pd.read_csv(CSV_PATH)\n", "    print(f\"Loaded predictions: {len(pred_df)} rows\")\n", "\n", "    # 2. RLE \ub514\ucf54\ub529 \ud568\uc218 (\uc218\uc815\ub428: 'nan' \ubb38\uc790\uc5f4 \ucc98\ub9ac \ucd94\uac00)\n", "    def decode_rle_to_mask(rle, height, width):\n", "        # rle\uac00 \uc2e4\uc81c NaN\uc774\uac70\ub098, \ubb38\uc790\uc5f4 \"nan\"\uc774\uba74 \ube48 \ub9c8\uc2a4\ud06c \ubc18\ud658\n", "        if pd.isna(rle) or str(rle).lower() == 'nan': \n", "            return np.zeros((height, width), dtype=np.uint8)\n", "        \n", "        s = str(rle).split() # \uc548\uc804\ud558\uac8c \ubb38\uc790\uc5f4\ub85c \ubcc0\ud658 \ud6c4 split\n", "        if not s: \n", "            return np.zeros((height, width), dtype=np.uint8)\n", "\n", "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n", "        starts -= 1\n", "        ends = starts + lengths\n", "        img = np.zeros(height * width, dtype=np.uint8)\n", "        \n", "        for lo, hi in zip(starts, ends):\n", "            img[lo:hi] = 1\n", "        \n", "        return img.reshape(height, width)\n", "\n", "    # 3. \ub9c8\uc2a4\ud06c -> FiftyOne Polyline \ubcc0\ud658 \ud568\uc218\n", "    def mask_to_polylines(mask, label, img_w, img_h):\n", "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n", "        polylines = []\n", "        for contour in contours:\n", "            if len(contour) < 3: continue\n", "            points = contour.squeeze().astype(float)\n", "            if len(points.shape) < 2: continue\n", "            \n", "            # \uc88c\ud45c \uc815\uaddc\ud654\n", "            points[:, 0] /= img_w\n", "            points[:, 1] /= img_h\n", "            \n", "            polylines.append(fo.Polyline(\n", "                label=label,\n", "                points=[points.tolist()],\n", "                closed=True,\n", "                filled=True\n", "            ))\n", "        return polylines\n", "\n", "    # 4. \ub370\uc774\ud130\uc14b\uc5d0 \uc608\uce21\uac12(Predictions) \ucd94\uac00\ud558\uae30\n", "    sample_map = {os.path.basename(s.filepath): s for s in dataset.match_tags(\"test\")}\n", "    print(\"Adding predictions to dataset...\")\n", "    grouped = pred_df.groupby(\"image_name\")\n", "\n", "    with dataset.save_context() as context:\n", "        for image_name, group in tqdm(grouped, total=len(grouped)):\n", "            if image_name not in sample_map:\n", "                continue\n", "            \n", "            sample = sample_map[image_name]\n", "            all_polylines = []\n", "            \n", "            for _, row in group.iterrows():\n", "                rle = row['rle']\n", "                label = row['class']\n", "                \n", "                # \uc5ec\uae30\uc11c str(rle)\ub97c \ud574\ub3c4 \ud568\uc218 \ub0b4\ubd80\uc5d0\uc11c 'nan' \uccb4\ud06c\ub97c \ud558\ubbc0\ub85c \uc548\uc804\ud568\n", "                mask = decode_rle_to_mask(rle, 2048, 2048)\n", "                \n", "                # \ub9c8\uc2a4\ud06c\uac00 \ube44\uc5b4\uc788\uc73c\uba74(0) polyline \ubcc0\ud658 \uc2a4\ud0b5\n", "                if mask.max() == 0:\n", "                    continue\n", "\n", "                polys = mask_to_polylines(mask, label, 2048, 2048)\n", "                all_polylines.extend(polys)\n", "            \n", "            if all_polylines:\n", "                sample[\"predictions\"] = fo.Polylines(polylines=all_polylines)\n", "                context.save(sample)\n", "\n", "    print(\"\u2705 Prediction update complete!\")\n"]}, {"cell_type": "code", "execution_count": null, "id": "a64e88a5", "metadata": {}, "outputs": [], "source": ["session = fo.launch_app(dataset, port=5151, auto=False)\n", "'''\n", "\ube0c\ub77c\uc6b0\uc800 \ucc3d\uc73c\ub85c \ubcf4\ub824\uba74 VS Code\uc5d0\uc11c \ud130\ubbf8\ub110 \uc606 Ports\uc5d0 5151 \ucd94\uac00 \ud6c4 localhost \uc811\uc18d\ud558\uba74 \ub429\ub2c8\ub2e4.\n", "'''"]}], "metadata": {"kernelspec": {"display_name": "home", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 5}