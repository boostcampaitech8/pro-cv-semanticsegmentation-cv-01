{"cells": [{"cell_type": "code", "execution_count": null, "id": "5c1bcbe6", "metadata": {}, "outputs": [], "source": ["# analyze_overlaps.ipynb\n", "# (\uc2dc\uac01\ud654 \uc81c\uac70 \ubc84\uc804 - \ube60\ub974\uace0 \uac04\ub2e8!)\n", "\n", "# ============================================\n", "# 1. \uacbd\ub85c \ud655\uc778 \ubc0f \uc124\uc815\n", "# ============================================\n", "\n", "import os\n", "import json\n", "import numpy as np\n", "import pandas as pd\n", "import cv2\n", "from tqdm import tqdm\n", "from itertools import combinations\n", "from collections import defaultdict\n", "\n", "# \uacbd\ub85c \uc124\uc815\n", "BASE_ROOT = \"/home/jkim0094/au31_scratch2/jkim0094/project5/data\"\n", "\n", "possible_paths = [\n", "    {\n", "        'image': os.path.join(BASE_ROOT, \"train/DCM\"),\n", "        'label': os.path.join(BASE_ROOT, \"train/outputs_json\")\n", "    },\n", "    {\n", "        'image': os.path.join(BASE_ROOT, \"ephemeral/home/data/train/DCM\"),\n", "        'label': os.path.join(BASE_ROOT, \"ephemeral/home/data/train/outputs_json\")\n", "    },\n", "]\n", "\n", "IMAGE_ROOT = None\n", "LABEL_ROOT = None\n", "\n", "print(\"\ud83d\udd0d Searching for correct paths...\\n\")\n", "for i, paths in enumerate(possible_paths, 1):\n", "    print(f\"Option {i}: {paths['image']}\")\n", "    if os.path.exists(paths['image']) and os.path.exists(paths['label']):\n", "        IMAGE_ROOT = paths['image']\n", "        LABEL_ROOT = paths['label']\n", "        print(f\"  \u2705 Found!\\n\")\n", "        break\n", "    else:\n", "        print(f\"  \u274c Not found\\n\")\n", "\n", "if IMAGE_ROOT is None:\n", "    print(\"\u274c Could not find data!\")\n", "    print(f\"\\n\ud83d\udd27 Please check manually:\")\n", "    print(f\"   ls {BASE_ROOT}\")\n", "    raise FileNotFoundError(\"Data not found\")\n", "\n", "print(\"=\"*60)\n", "print(f\"\u2705 IMAGE_ROOT: {IMAGE_ROOT}\")\n", "print(f\"\u2705 LABEL_ROOT: {LABEL_ROOT}\")\n", "print(\"=\"*60)\n", "\n", "# ============================================\n", "# 2. \ud30c\uc77c \uc218\uc9d1\n", "# ============================================\n", "\n", "print(\"\\n\ud83d\udd0d Collecting files...\")\n", "\n", "jsons = []\n", "for root, dirs, files in os.walk(LABEL_ROOT):\n", "    for fname in files:\n", "        if fname.endswith('.json'):\n", "            rel_path = os.path.relpath(os.path.join(root, fname), LABEL_ROOT)\n", "            jsons.append(rel_path)\n", "\n", "jsons = sorted(jsons)\n", "\n", "print(f'\u2705 Found {len(jsons)} JSON files')\n", "if len(jsons) > 0:\n", "    print(f'   Example: {jsons[0]}')\n", "else:\n", "    raise FileNotFoundError(\"No JSON files found!\")\n", "\n", "# ============================================\n", "# 3. \ud074\ub798\uc2a4 \uc815\uc758\n", "# ============================================\n", "\n", "CLASSES = [\n", "    'finger-1', 'finger-2', 'finger-3', 'finger-4', 'finger-5',\n", "    'finger-6', 'finger-7', 'finger-8', 'finger-9', 'finger-10',\n", "    'finger-11', 'finger-12', 'finger-13', 'finger-14', 'finger-15',\n", "    'finger-16', 'finger-17', 'finger-18', 'finger-19', 'Trapezium',\n", "    'Trapezoid', 'Capitate', 'Hamate', 'Scaphoid', 'Lunate',\n", "    'Triquetrum', 'Pisiform', 'Radius', 'Ulna',\n", "]\n", "CLASS2IND = {v: i for i, v in enumerate(CLASSES)}\n", "\n", "print(f'\\n\ud83d\udcda Total classes: {len(CLASSES)}')\n", "\n", "# ============================================\n", "# 4. \ub9c8\uc2a4\ud06c \uc0dd\uc131 \ud568\uc218\n", "# ============================================\n", "\n", "def create_mask_from_json(json_path, image_size=(2048, 2048)):\n", "    \"\"\"JSON \ud30c\uc77c\uc5d0\uc11c \uac01 \ud074\ub798\uc2a4\ubcc4 \ub9c8\uc2a4\ud06c \uc0dd\uc131\"\"\"\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "    \n", "    masks = np.zeros((len(CLASSES), image_size[0], image_size[1]), dtype=np.uint8)\n", "    \n", "    annotations = data.get('annotations', [])\n", "    for ann in annotations:\n", "        label = ann.get('label')\n", "        points = ann.get('points', [])\n", "        \n", "        if label in CLASS2IND and len(points) > 2:\n", "            class_idx = CLASS2IND[label]\n", "            pts_array = np.array(points, dtype=np.int32)\n", "            cv2.fillPoly(masks[class_idx], [pts_array], 1)\n", "    \n", "    return masks\n", "\n", "# ============================================\n", "# 5. Overlap \ubd84\uc11d (\ud575\uc2ec!)\n", "# ============================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"\ud83d\udd0d Starting Overlap Analysis...\")\n", "print(\"=\"*60)\n", "\n", "overlap_stats = defaultdict(lambda: {\n", "    'total_pixels': 0,\n", "    'num_images': 0,\n", "    'per_image_pixels': []\n", "})\n", "\n", "print(f\"\\nProcessing {len(jsons)} images...\")\n", "for json_file in tqdm(jsons, desc=\"Analyzing\"):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    \n", "    # \ub9c8\uc2a4\ud06c \uc0dd\uc131\n", "    masks = create_mask_from_json(json_path)\n", "    \n", "    # \uc874\uc7ac\ud558\ub294 \ud074\ub798\uc2a4 \ud655\uc778\n", "    present_classes = [i for i in range(29) if masks[i].sum() > 0]\n", "    \n", "    # 2\uac1c \uc870\ud569 \ud655\uc778\n", "    for cls_a, cls_b in combinations(present_classes, 2):\n", "        overlap = (masks[cls_a] == 1) & (masks[cls_b] == 1)\n", "        overlap_pixels = overlap.sum()\n", "        \n", "        if overlap_pixels > 0:\n", "            pair = tuple(sorted([cls_a, cls_b]))\n", "            overlap_stats[pair]['total_pixels'] += overlap_pixels\n", "            overlap_stats[pair]['num_images'] += 1\n", "            overlap_stats[pair]['per_image_pixels'].append(overlap_pixels)\n", "\n", "# ============================================\n", "# 6. \uacb0\uacfc \uc815\ub9ac\n", "# ============================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"\ud83d\udcca Calculating Statistics...\")\n", "print(\"=\"*60)\n", "\n", "results = []\n", "for pair, stats in overlap_stats.items():\n", "    cls_a, cls_b = pair\n", "    avg_pixels = stats['total_pixels'] / stats['num_images']\n", "    \n", "    results.append({\n", "        'class_a': CLASSES[cls_a],\n", "        'class_b': CLASSES[cls_b],\n", "        'class_a_idx': cls_a,\n", "        'class_b_idx': cls_b,\n", "        'total_overlap_pixels': stats['total_pixels'],\n", "        'num_images_overlap': stats['num_images'],\n", "        'avg_overlap_pixels': avg_pixels,\n", "        'max_overlap_pixels': max(stats['per_image_pixels']),\n", "        'min_overlap_pixels': min(stats['per_image_pixels']),\n", "    })\n", "\n", "df_overlap = pd.DataFrame(results)\n", "df_overlap = df_overlap.sort_values('avg_overlap_pixels', ascending=False)\n", "\n", "print(f\"\\n\u2705 Total pairs with overlap: {len(df_overlap)}\")\n", "print(f\"   (Out of {len(list(combinations(range(29), 2)))} possible)\")\n", "\n", "# ============================================\n", "# 7. \uacb0\uacfc \ucd9c\ub825\n", "# ============================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"\ud83c\udfc6 Top 20 Most Overlapping Pairs\")\n", "print(\"=\"*60)\n", "for idx, row in df_overlap.head(20).iterrows():\n", "    print(f\"{row['class_a']:15} \u2194 {row['class_b']:15} : \"\n", "          f\"{row['avg_overlap_pixels']:7.0f} px  \"\n", "          f\"({row['num_images_overlap']:3} images)\")\n", "\n", "# ============================================\n", "# 8. \uc784\uacc4\uac12\ubcc4 \ud544\ud130\ub9c1\n", "# ============================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"\ud83d\udccf Filtering by Threshold\")\n", "print(\"=\"*60)\n", "\n", "thresholds = [50, 100, 200, 500, 1000]\n", "for threshold in thresholds:\n", "    filtered = df_overlap[df_overlap['avg_overlap_pixels'] >= threshold]\n", "    print(f\"\\n\u2265 {threshold:4} pixels: {len(filtered):2} pairs\")\n", "    if len(filtered) > 0 and len(filtered) <= 10:\n", "        for _, row in filtered.iterrows():\n", "            print(f\"  - {row['class_a']:15} \u2194 {row['class_b']:15} : {row['avg_overlap_pixels']:7.0f} px\")\n", "\n", "# ============================================\n", "# 9. JSON \uc800\uc7a5\n", "# ============================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"\ud83d\udcbe Saving Results...\")\n", "print(\"=\"*60)\n", "\n", "SAVE_THRESHOLD = 100\n", "\n", "filtered_pairs = df_overlap[df_overlap['avg_overlap_pixels'] >= SAVE_THRESHOLD]\n", "\n", "output_data = {\n", "    'metadata': {\n", "        'total_images_analyzed': len(jsons),\n", "        'threshold_pixels': SAVE_THRESHOLD,\n", "        'total_pairs_found': len(filtered_pairs),\n", "        'analysis_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n", "    },\n", "    'pairs': []\n", "}\n", "\n", "for _, row in filtered_pairs.iterrows():\n", "    output_data['pairs'].append({\n", "        'classes': [int(row['class_a_idx']), int(row['class_b_idx'])],\n", "        'class_names': [row['class_a'], row['class_b']],\n", "        'avg_overlap_pixels': float(row['avg_overlap_pixels']),\n", "        'total_overlap_pixels': int(row['total_overlap_pixels']),\n", "        'num_images': int(row['num_images_overlap']),\n", "    })\n", "\n", "# \uc800\uc7a5\n", "output_file = 'overlap_pairs.json'\n", "with open(output_file, 'w') as f:\n", "    json.dump(output_data, f, indent=2)\n", "\n", "print(f\"\\n\u2705 Saved to: {output_file}\")\n", "print(f\"   Threshold: {SAVE_THRESHOLD} pixels\")\n", "print(f\"   Pairs saved: {len(output_data['pairs'])}\")\n", "\n", "print(\"\\n\ud83d\udccb Saved pairs:\")\n", "for pair in output_data['pairs']:\n", "    print(f\"  {pair['class_names'][0]:15} \u2194 {pair['class_names'][1]:15} : \"\n", "          f\"{pair['avg_overlap_pixels']:7.0f} px  \"\n", "          f\"({pair['num_images']} imgs)\")\n", "\n", "# ============================================\n", "# 10. \uc644\ub8cc\n", "# ============================================\n", "\n", "print(\"\\n\" + \"=\"*60)\n", "print(\"\u2705 Analysis Complete!\")\n", "print(\"=\"*60)\n", "print(f\"\\nSummary:\")\n", "print(f\"  \ud83d\udcca Images analyzed: {len(jsons)}\")\n", "print(f\"  \ud83d\udd17 Pairs with overlap: {len(df_overlap)}\")\n", "print(f\"  \u2728 Pairs \u2265 {SAVE_THRESHOLD}px: {len(filtered_pairs)}\")\n", "print(f\"  \ud83d\udcbe Output: {output_file}\")\n", "\n", "print(\"\\n\ud83d\udcdd Next steps:\")\n", "print(\"  1. Check 'overlap_pairs.json' file\")\n", "print(\"  2. Update config.py:\")\n", "print(\"     OVERLAP_ANALYSIS_FILE = 'overlap_pairs.json'\")\n", "print(\"  3. Modify util.py to load this file\")\n", "print(\"  4. Run training with Overlap Loss!\")\n", "\n", "print(\"\\n\" + \"=\"*60)"]}], "metadata": {"kernelspec": {"display_name": ".venv", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.13"}}, "nbformat": 4, "nbformat_minor": 5}