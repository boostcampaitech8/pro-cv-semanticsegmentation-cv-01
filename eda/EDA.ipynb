{"cells": [{"cell_type": "markdown", "id": "8a8436d2", "metadata": {}, "source": ["# Setting"]}, {"cell_type": "code", "execution_count": null, "id": "9e409e54", "metadata": {}, "outputs": [], "source": ["import os\n", "import json\n", "import numpy as np\n", "import pandas as pd\n", "import cv2\n", "import matplotlib.pyplot as plt\n", "import plotly.express as px\n", "import plotly.graph_objects as go\n", "import seaborn as sns\n", "from tqdm import tqdm\n", "from itertools import combinations\n", "import re\n"]}, {"cell_type": "code", "execution_count": null, "id": "df7ffa88", "metadata": {}, "outputs": [], "source": ["IMAGE_ROOT = \"/data/ephemeral/home/data/train/DCM\"\n", "LABEL_ROOT = \"/data/ephemeral/home/data/train/outputs_json\""]}, {"cell_type": "code", "execution_count": null, "id": "2505d532", "metadata": {}, "outputs": [], "source": ["pngs = {\n", "    os.path.relpath(os.path.join(root, fname), start=IMAGE_ROOT)\n", "    for root, _dirs, files in os.walk(IMAGE_ROOT)\n", "    for fname in files\n", "    if os.path.splitext(fname)[1].lower() == \".png\"\n", "}\n", "jsons = {\n", "    os.path.relpath(os.path.join(root, fname), start=LABEL_ROOT)\n", "    for root, _dirs, files in os.walk(LABEL_ROOT)\n", "    for fname in files\n", "    if os.path.splitext(fname)[1].lower() == \".json\"\n", "}\n", "print(f'Train Image : {len(pngs)}, json : {len(jsons)}')\n", "\n", "pngs = sorted(list(pngs))\n", "jsons = sorted(list(jsons))\n", "print(f'Image file name e.g.) {pngs[0]}\\njson file name e.g.) {jsons[0]}')"]}, {"cell_type": "code", "execution_count": null, "id": "ec8f02c3", "metadata": {}, "outputs": [], "source": ["def read_json_and_inspect(json_rel_path):\n", "    json_path = os.path.join(LABEL_ROOT, json_rel_path)\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "    return data\n", "\n", "# \uccab \ubc88\uc9f8 JSON \ud30c\uc77c \uad6c\uc870 \ud655\uc778\n", "sample_json_path = jsons[0]\n", "sample_data = read_json_and_inspect(sample_json_path)\n", "\n", "print(f\"File: {sample_json_path}\")\n", "print(\"Keys:\", sample_data.keys())\n", "# 'annotations' \ud0a4\uac00 \uc788\ub294\uc9c0, \ub0b4\ubd80 \uad6c\uc870\uac00 \uc5b4\ub5a4\uc9c0 \ud655\uc778\uc6a9 \ucd9c\ub825\n", "if 'annotations' in sample_data:\n", "    print(\"First annotation example:\", sample_data['annotations'][0])"]}, {"cell_type": "code", "execution_count": null, "id": "cf022089", "metadata": {}, "outputs": [], "source": ["COLORS = np.random.randint(0, 255, size=(30, 3), dtype=\"uint8\")\n", "\n", "def visualize_sample(index, alpha=0.4):\n", "\n", "    png_filename = pngs[index]\n", "    json_filename = jsons[index]\n", "\n", "    img_path = os.path.join(IMAGE_ROOT, png_filename)\n", "    json_path = os.path.join(LABEL_ROOT, json_filename)\n", "    \n", "    img = cv2.imread(img_path)\n", "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n", "    \n", "    original_img = img.copy()  # \uc67c\ucabd \ud654\uba74\uc6a9 (\uae68\ub057\ud55c \uc6d0\ubcf8)\n", "    vis_img = img.copy()       # \uc624\ub978\ucabd \ud654\uba74\uc6a9 (\uadf8\ub9bc \uadf8\ub9b4 \ub300\uc0c1)\n", "    overlay = img.copy()       # \ud22c\uba85\ub3c4 \uc870\uc808\uc6a9\n", "    \n", "    # JSON \ub85c\ub4dc\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "\n", "    annotations = data.get('annotations', [])\n", "    print(f\"Image: {png_filename}\")\n", "    print(f\"Number of annotations: {len(annotations)}\")\n", "    \n", "    class_names_in_img = set()\n", "    \n", "    for ann in annotations:\n", "        label = ann.get('label', 'unknown')\n", "        points = ann.get('points', [])\n", "        \n", "        class_names_in_img.add(label)\n", "        \n", "        # \ud3ec\uc778\ud2b8\ub97c numpy \ubc30\uc5f4\ub85c \ubcc0\ud658\n", "        pts = np.array(points, np.int32)\n", "        pts = pts.reshape((-1, 1, 2))\n", "        \n", "        # \ud074\ub798\uc2a4 \uc774\ub984\uc5d0 \ub530\ub77c \uc0c9\uc0c1 \uacb0\uc815\n", "        color_idx = hash(label) % len(COLORS)\n", "        color = COLORS[color_idx].tolist()\n", "        \n", "        cv2.fillPoly(overlay, [pts], color)\n", "        cv2.polylines(vis_img, [pts], True, color, 2)\n", "        \n", "    vis_img = cv2.addWeighted(overlay, alpha, vis_img, 1 - alpha, 0)\n", "    \n", "    fig, axes = plt.subplots(1, 2, figsize=(20, 10)) \n", "    \n", "    # \uc67c\ucabd: \uc6d0\ubcf8 \uc774\ubbf8\uc9c0\n", "    axes[0].imshow(original_img)\n", "    axes[0].set_title(\"Original Image\", fontsize=15)\n", "    axes[0].axis('off')\n", "    \n", "    # \uc624\ub978\ucabd: \ud3f4\ub9ac\uace4 \uc801\uc6a9 \uc774\ubbf8\uc9c0\n", "    axes[1].imshow(vis_img)\n", "    axes[1].set_title(f\"With Annotations\\n({', '.join(list(class_names_in_img))[:40]}...)\", fontsize=15)\n", "    axes[1].axis('off')\n", "    \n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "import random\n", "random_idx = random.randint(0, len(pngs)-1)\n", "visualize_sample(random_idx)"]}, {"cell_type": "markdown", "id": "67af6cf6", "metadata": {}, "source": ["# EDA "]}, {"cell_type": "code", "execution_count": null, "id": "c6d0dc2b", "metadata": {}, "outputs": [], "source": ["area_data = []\n", "\n", "print(\"Calculating area for all annotations...\")\n", "for json_file in tqdm(jsons):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    \n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "        \n", "    annotations = data.get('annotations', [])\n", "    for ann in annotations:\n", "        label = ann.get('label')\n", "        points = ann.get('points', [])\n", "        \n", "        if label and len(points) > 2:\n", "            pts_array = np.array(points, dtype=np.int32)\n", "            area = cv2.contourArea(pts_array)\n", "            \n", "            area_data.append({\n", "                'label': label,\n", "                'area': area\n", "            })\n", "\n", "df_area = pd.DataFrame(area_data)\n", "annotation_order = df_area['label'].unique().tolist()\n", "\n", "# Box Plot\n", "fig = px.box(\n", "    df_area, \n", "    x='area', \n", "    y='label', \n", "    color='label',          \n", "    log_x=True,             \n", "    points=\"outliers\",      \n", "    title=\"Distribution of Annotation Areas per Class (Log Scale)\",\n", "    template='plotly_white', \n", "    category_orders={'label': annotation_order} \n", ")\n", "\n", "fig.update_layout(\n", "    xaxis_title=\"Area (pixels) - Log Scale\",\n", "    yaxis_title=\"Class Name\",\n", "    showlegend=False,   \n", "    height=max(600, 30 * len(annotation_order)), \n", "    margin=dict(l=50, r=50, t=80, b=50)\n", ")\n", "\n", "fig.update_traces(hovertemplate='<b>%{y}</b><br>Area: %{x}')\n", "fig.show()\n", "\n", "print(\"\\nTop 5 Smallest Classes (Average Area)\")\n", "print(df_area.groupby('label')['area'].mean().sort_values().head(5))\n", "\n", "print(\"\\nTop 5 Largest Classes (Average Area)\")\n", "print(df_area.groupby('label')['area'].mean().sort_values().tail(5))"]}, {"cell_type": "code", "execution_count": null, "id": "14fd7f2e", "metadata": {}, "outputs": [], "source": ["SAMPLE_IMAGES = 100  # \uc804\uccb4\ub97c \ub2e4 \ud558\uba74 \ub290\ub9ac\ubbc0\ub85c 100\uc7a5\ub9cc \uc0d8\ud50c\ub9c1\n", "PIXEL_SAMPLE_SIZE = 5000 # \uc774\ubbf8\uc9c0\ub2f9 \ucd94\ucd9c\ud560 \ud53d\uc140 \uc218\n", "\n", "intensity_data = []\n", "\n", "print(f\"Analyzing Pixel Intensity from {SAMPLE_IMAGES} sample images...\")\n", "\n", "# \ub79c\ub364\ud558\uac8c \uc774\ubbf8\uc9c0 \uc120\ud0dd\n", "import random\n", "sample_indices = random.sample(range(len(jsons)), min(len(jsons), SAMPLE_IMAGES))\n", "sample_jsons = [jsons[i] for i in sample_indices]\n", "\n", "for json_file in tqdm(sample_jsons):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "    \n", "    png_filename = json_file.replace('.json', '.png')\n", "    img_path = os.path.join(IMAGE_ROOT, png_filename)\n", "    \n", "    # Grayscale \ub85c\ub4dc\n", "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n", "    if img is None: continue\n", "    \n", "    # Mask \uc0dd\uc131 (0: \ubc30\uacbd, 1: \ubf08)\n", "    mask = np.zeros_like(img, dtype=np.uint8)\n", "    \n", "    annotations = data.get('annotations', [])\n", "    for ann in annotations:\n", "        points = ann.get('points', [])\n", "        if len(points) > 2:\n", "            pts = np.array(points, np.int32)\n", "            cv2.fillPoly(mask, [pts], 1)\n", "            \n", "    # \ud53d\uc140 \ucd94\ucd9c\n", "    bone_pixels = img[mask == 1]\n", "    bg_pixels = img[mask == 0]\n", "    \n", "    # \ub370\uc774\ud130\uac00 \ub108\ubb34 \ub9ce\uc73c\uba74 \uc2dc\uac01\ud654\uac00 \ub290\ub9ac\ubbc0\ub85c \ub79c\ub364 \uc0d8\ud50c\ub9c1\ud574\uc11c \uc800\uc7a5\n", "    if len(bone_pixels) > 0:\n", "        sampled = np.random.choice(bone_pixels, size=min(len(bone_pixels), PIXEL_SAMPLE_SIZE // 2))\n", "        for p in sampled:\n", "            intensity_data.append({'Intensity': p, 'Type': 'Bone'})\n", "            \n", "    if len(bg_pixels) > 0:\n", "        sampled = np.random.choice(bg_pixels, size=min(len(bg_pixels), PIXEL_SAMPLE_SIZE // 2))\n", "        for p in sampled:\n", "            intensity_data.append({'Intensity': p, 'Type': 'Background'})\n", "\n", "df_intensity = pd.DataFrame(intensity_data)\n", "\n", "# \uc2dc\uac01\ud654\n", "plt.figure(figsize=(10, 6))\n", "sns.kdeplot(data=df_intensity, x='Intensity', hue='Type', fill=True, \n", "            palette={'Bone': 'orange', 'Background': 'skyblue'}, alpha=0.5)\n", "\n", "plt.title(\"Pixel Intensity Distribution: Bone vs Background\")\n", "plt.xlabel(\"Pixel Value (0=Black, 255=White)\")\n", "plt.grid(True, alpha=0.3)\n", "plt.show()\n", "\n", "# \ud1b5\uacc4\uc801 \uc218\uce58 \ud655\uc778 (\ud3c9\uade0 \ubc1d\uae30 \ucc28\uc774)\n", "print(df_intensity.groupby('Type')['Intensity'].describe()[['mean', 'std']])"]}, {"cell_type": "code", "execution_count": null, "id": "4e68f5cf", "metadata": {}, "outputs": [], "source": ["centroid_data = []\n", "\n", "print(\"Analyzing Anatomical Spatial Consistency (Centroids)...\")\n", "\n", "for json_file in tqdm(jsons):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "        \n", "    annotations = data.get('annotations', [])\n", "    \n", "    for ann in annotations:\n", "        label = ann.get('label')\n", "        points = ann.get('points', [])\n", "        \n", "        if len(points) > 2:\n", "            pts = np.array(points, np.int32)\n", "            \n", "            # \ubb34\uac8c\uc911\uc2ec (Centroid) \uacc4\uc0b0 (Moments \uc774\uc6a9)\n", "            M = cv2.moments(pts)\n", "            if M[\"m00\"] != 0:\n", "                cX = int(M[\"m10\"] / M[\"m00\"])\n", "                cY = int(M[\"m01\"] / M[\"m00\"])\n", "                \n", "                centroid_data.append({\n", "                    'label': label,\n", "                    'x': cX,\n", "                    'y': cY,\n", "                    'file': json_file\n", "                })\n", "\n", "df_centroid = pd.DataFrame(centroid_data)\n", "\n", "# \uc2dc\uac01\ud654 (Scatter Plot)\n", "plt.figure(figsize=(10, 10))\n", "\n", "# \uc804\uccb4 \ubd84\ud3ec, \uc0c9\uc0c1\uc73c\ub85c \uad6c\ubd84\n", "sns.scatterplot(data=df_centroid, x='x', y='y', hue='label', s=10, alpha=0.6, legend=False)\n", "\n", "# \uc774\ubbf8\uc9c0 \uc88c\ud45c\uacc4\uc5d0 \ub9de\ucdb0 Y\ucd95 \ubc18\uc804 (\uc774\ubbf8\uc9c0\ub294 \uc704\uac00 0)\n", "plt.gca().invert_yaxis()\n", "plt.title(\"Centroid Distribution of All Bones (Anatomical Consistency)\")\n", "plt.xlabel(\"X Coordinate\")\n", "plt.ylabel(\"Y Coordinate\")\n", "plt.grid(True, linestyle='--', alpha=0.5)\n", "\n", "plt.xlim(0, 2048)\n", "plt.ylim(2048, 0) \n", "\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "id": "79cc8cd8", "metadata": {}, "outputs": [], "source": ["IMG_H, IMG_W = 2048, 2048 \n", "overlap_accumulator = np.zeros((IMG_H, IMG_W), dtype=np.float32)\n", "\n", "print(\"Calculating Bone Overlap Heatmap...\")\n", "\n", "count = 0\n", "for json_file in tqdm(jsons):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "        \n", "    annotations = data.get('annotations', [])\n", "    \n", "    # \uc774\ubbf8\uc9c0 \ud55c \uc7a5\uc5d0 \ub300\ud55c \ub808\uc774\uc5b4 (0\uc73c\ub85c \ucd08\uae30\ud654)\n", "    # \uc5ec\uae30\uc5d0 \ubf08\ub97c \ud558\ub098\uc529 \uadf8\ub9b4 \ub54c\ub9c8\ub2e4 +1\uc744 \ud569\ub2c8\ub2e4.\n", "    current_img_layer = np.zeros((IMG_H, IMG_W), dtype=np.uint8)\n", "    \n", "    for ann in annotations:\n", "        points = ann.get('points', [])\n", "        if len(points) > 2:\n", "            pts = np.array(points, np.int32)\n", "            \n", "            # \ubf08 \ud558\ub098\ub97c \uc784\uc2dc \ub9c8\uc2a4\ud06c\uc5d0 \uadf8\ub9bd\ub2c8\ub2e4 (\uac12 1)\n", "            temp_mask = np.zeros((IMG_H, IMG_W), dtype=np.uint8)\n", "            cv2.fillPoly(temp_mask, [pts], 1)\n", "            \n", "            # \uc804\uccb4 \ub808\uc774\uc5b4\uc5d0 \ub354\ud569\ub2c8\ub2e4.\n", "            current_img_layer += temp_mask\n", "            \n", "    # \uacb9\uce58\ub294 \ubd80\ubd84 \ucc3e\uae30: \ud53d\uc140 \uac12\uc774 2 \uc774\uc0c1\uc778 \uacf3\uc774 \uacb9\uce5c \uacf3\uc785\ub2c8\ub2e4.\n", "    # (0: \ubc30\uacbd, 1: \ubf08 1\uac1c, 2 \uc774\uc0c1: \ubf08 \uacb9\uce68)\n", "    overlap_mask = (current_img_layer > 1).astype(np.float32)\n", "    \n", "    # \uc804\uccb4 \ub370\uc774\ud130\uc14b \ub204\uc801\n", "    overlap_accumulator += overlap_mask\n", "    count += 1\n", "\n", "plt.figure(figsize=(12, 10))\n", "\n", "overlap_vis = np.copy(overlap_accumulator)\n", "overlap_vis[overlap_vis == 0] = np.nan \n", "\n", "# Heatmap \uadf8\ub9ac\uae30 ('magma' colormap \ucd94\ucc9c: \uac80\uc815->\ubcf4\ub77c->\ube68\uac15->\ub178\ub791)\n", "# \ub178\ub780\uc0c9\uc77c\uc218\ub85d \"\uc774 \uc704\uce58\uc5d0\uc11c \ubf08\ub4e4\uc774 \uc5c4\uccad \uc790\uc8fc \uacb9\uce5c\ub2e4\"\ub294 \ub73b\uc785\ub2c8\ub2e4.\n", "plt.imshow(overlap_vis, cmap='magma', interpolation='nearest')\n", "plt.colorbar(label='Frequency of Overlaps')\n", "\n", "plt.title(f\"Bone Overlap Heatmap (Aggregated over {count} images)\")\n", "plt.axis('off')\n", "\n", "plt.show()\n", "\n", "# \ud1b5\uacc4 \ucd9c\ub825\n", "total_pixels = IMG_H * IMG_W * count\n", "overlap_pixels = np.sum(overlap_accumulator)\n", "print(f\"\uc774\ubbf8\uc9c0 \ud55c \uc7a5\ub2f9 \ud3c9\uade0\uc801\uc73c\ub85c \uc57d {np.sum(overlap_accumulator)/count:.0f} \ud53d\uc140\uc774 \uacb9\uce68 \uad6c\uac04\uc785\ub2c8\ub2e4.\")"]}, {"cell_type": "code", "execution_count": null, "id": "76210e76", "metadata": {}, "outputs": [], "source": ["SCALE_FACTOR = 0.25  \n", "img_w, img_h = 2048, 2048 \n", "w_small, h_small = int(img_w * SCALE_FACTOR), int(img_h * SCALE_FACTOR)\n", "\n", "with open(os.path.join(LABEL_ROOT, jsons[0]), 'r') as f:\n", "    first_data = json.load(f)\n", "    class_list = [ann['label'] for ann in first_data['annotations']]\n", "\n", "class_to_idx = {name: i for i, name in enumerate(class_list)}\n", "n_classes = len(class_list)\n", "\n", "# \uacb0\uacfc \uc800\uc7a5\uc6a9 \ud589\ub82c\n", "# [i, j] = i\ubc88\uc9f8 \ud074\ub798\uc2a4\uc640 j\ubc88\uc9f8 \ud074\ub798\uc2a4\uc758 \uacb9\uce68 \uc815\ubcf4\n", "iou_sum_matrix = np.zeros((n_classes, n_classes))\n", "overlap_count_matrix = np.zeros((n_classes, n_classes))\n", "\n", "print(f\"Calculating Overlap Matrix for {n_classes} classes...\")\n", "\n", "# \uad50\uc9d1\ud569 \ubc0f IoU \uacc4\uc0b0\n", "for json_file in tqdm(jsons):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "    \n", "    annotations = data.get('annotations', [])\n", "    \n", "    # \ud604\uc7ac \uc774\ubbf8\uc9c0\uc758 \ub9c8\uc2a4\ud06c\ub4e4\uc744 \uc800\uc7a5\ud560 \ub515\uc154\ub108\ub9ac\n", "    masks = {}\n", "    bboxes = {}\n", "\n", "    # 1. \ub9c8\uc2a4\ud06c \uc0dd\uc131 (\uc2a4\ucf00\uc77c \uc904\uc5ec\uc11c)\n", "    for ann in annotations:\n", "        label = ann.get('label')\n", "        points = ann.get('points', [])\n", "        \n", "        if label in class_to_idx and len(points) > 2:\n", "            # \uc88c\ud45c \uc2a4\ucf00\uc77c\ub9c1\n", "            pts = (np.array(points) * SCALE_FACTOR).astype(np.int32)\n", "            \n", "            # \ub9c8\uc2a4\ud06c \uadf8\ub9ac\uae30\n", "            mask = np.zeros((h_small, w_small), dtype=np.uint8)\n", "            cv2.fillPoly(mask, [pts], 1)\n", "            \n", "            masks[label] = mask\n", "            \n", "            # Bounding Box (\ube60\ub978 \uacc4\uc0b0\uc6a9)\n", "            x, y, w, h = cv2.boundingRect(pts)\n", "            bboxes[label] = (x, y, x+w, y+h)\n", "\n", "    # 2. \ubaa8\ub4e0 \uc30d(Pair)\uc5d0 \ub300\ud574 \uacb9\uce68 \ud655\uc778\n", "    # itertools.combinations\ub97c \uc368\uc11c (A, B) \uc30d\uc744 \uc0dd\uc131\n", "    for label_a, label_b in combinations(class_list, 2):\n", "        if label_a not in masks or label_b not in masks:\n", "            continue\n", "            \n", "        # BBox \uba3c\uc800 \ud655\uc778 (\uc548 \uacb9\uce58\uba74 \ud328\uc2a4)\n", "        xa1, ya1, xa2, ya2 = bboxes[label_a]\n", "        xb1, yb1, xb2, yb2 = bboxes[label_b]\n", "        \n", "        # \uc0ac\uac01\ud615\uc774 \uacb9\uce58\uc9c0 \uc54a\ub294 \uc870\uac74\n", "        if xa2 < xb1 or xb2 < xa1 or ya2 < yb1 or yb2 < ya1:\n", "            continue\n", "            \n", "        # \uc2e4\uc81c \ub9c8\uc2a4\ud06c \uad50\uc9d1\ud569 \uc5f0\uc0b0\n", "        mask_a = masks[label_a]\n", "        mask_b = masks[label_b]\n", "        \n", "        intersection = np.logical_and(mask_a, mask_b).sum()\n", "        \n", "        if intersection > 0:\n", "            union = np.logical_or(mask_a, mask_b).sum()\n", "            iou = intersection / union if union > 0 else 0\n", "            \n", "            idx_a, idx_b = class_to_idx[label_a], class_to_idx[label_b]\n", "            \n", "            # \ud589\ub82c\uc5d0 \ub204\uc801 (\ub300\uce6d \ud589\ub82c)\n", "            iou_sum_matrix[idx_a, idx_b] += iou\n", "            iou_sum_matrix[idx_b, idx_a] += iou\n", "            \n", "            overlap_count_matrix[idx_a, idx_b] += 1\n", "            overlap_count_matrix[idx_b, idx_a] += 1\n", "\n", "# \ud3c9\uade0 IoU \uacc4\uc0b0 (\uacb9\uce5c \uc801\uc774 \uc788\ub294 \uacbd\uc6b0\uc5d0\ub9cc \ud3c9\uade0)\n", "# 0\uc73c\ub85c \ub098\ub204\uae30 \ubc29\uc9c0\n", "avg_iou_matrix = np.divide(iou_sum_matrix, overlap_count_matrix, \n", "                           out=np.zeros_like(iou_sum_matrix), \n", "                           where=overlap_count_matrix!=0)\n", "\n", "# \uc790\uae30 \uc790\uc2e0\uacfc\uc758 \uad00\uacc4\ub294 \uc758\ubbf8 \uc5c6\uc73c\ubbc0\ub85c 0 \ub610\ub294 1 (\uc5ec\uae30\uc120 \uc2dc\uac01\ud654 \ud3b8\uc758\uc0c1 0)\n", "np.fill_diagonal(avg_iou_matrix, 0)\n", "np.fill_diagonal(overlap_count_matrix, 0)\n", "\n", "# 3. Plotly Heatmap \uc2dc\uac01\ud654\n", "# (1) \ud3c9\uade0 IoU \ud788\ud2b8\ub9f5 (\uc5bc\ub9c8\ub098 \uc2ec\ud558\uac8c \uacb9\uce58\ub098?)\n", "fig_iou = px.imshow(\n", "    avg_iou_matrix,\n", "    x=class_list,\n", "    y=class_list,\n", "    color_continuous_scale='Reds',\n", "    title=\"Average IoU Heatmap (Severity of Overlap)\",\n", "    labels=dict(x=\"Class A\", y=\"Class B\", color=\"Avg IoU\"),\n", "    template='plotly_white'\n", ")\n", "fig_iou.update_layout(\n", "    width=900, height=900,\n", "    xaxis_title=\"Class Name\", yaxis_title=\"Class Name\"\n", ")\n", "# \ub9c8\uc6b0\uc2a4 \uc62c\ub838\uc744 \ub54c \uc815\ubcf4 \ud45c\uc2dc\n", "fig_iou.update_traces(\n", "    hovertemplate=\"<b>%{x}</b> & <b>%{y}</b><br>Avg IoU: %{z:.3f}<extra></extra>\"\n", ")\n", "fig_iou.show()\n", "\n", "\n", "# (2) \uacb9\uce68 \ube48\ub3c4 \ud788\ud2b8\ub9f5 (\uc5bc\ub9c8\ub098 \uc790\uc8fc \uacb9\uce58\ub098?)\n", "fig_count = px.imshow(\n", "    overlap_count_matrix,\n", "    x=class_list,\n", "    y=class_list,\n", "    color_continuous_scale='Blues',\n", "    title=f\"Overlap Frequency Heatmap (Count out of {len(jsons)} images)\",\n", "    labels=dict(x=\"Class A\", y=\"Class B\", color=\"Count\"),\n", "    template='plotly_white'\n", ")\n", "fig_count.update_layout(\n", "    width=900, height=900,\n", "    xaxis_title=\"Class Name\", yaxis_title=\"Class Name\"\n", ")\n", "fig_count.update_traces(\n", "    hovertemplate=\"<b>%{x}</b> & <b>%{y}</b><br>Overlap Count: %{z} times<extra></extra>\"\n", ")\n", "fig_count.show()\n", "\n", "# \uac00\uc7a5 \uc2ec\uac01\ud55c \uacb9\uce68 Top 10 \ucd9c\ub825\n", "# \uc0c1\uc0bc\uac01\ud589\ub82c(Upper Triangle)\ub9cc \ucd94\ucd9c\ud574\uc11c \uc911\ubcf5 \uc81c\uac70\n", "triu_indices = np.triu_indices(n_classes, k=1)\n", "overlap_list = []\n", "\n", "for i, j in zip(*triu_indices):\n", "    if overlap_count_matrix[i, j] > 0:\n", "        overlap_list.append({\n", "            'Class A': class_list[i],\n", "            'Class B': class_list[j],\n", "            'Frequency': int(overlap_count_matrix[i, j]),\n", "            'Avg IoU': avg_iou_matrix[i, j]\n", "        })\n", "\n", "df_overlap = pd.DataFrame(overlap_list)\n", "print(\"\\n=== Top 10 Most Frequently Overlapping Pairs ===\")\n", "print(df_overlap.sort_values('Frequency', ascending=False).head(10))\n", "\n", "print(\"\\n=== Top 10 Most Severely Overlapping Pairs (High IoU) ===\")\n", "print(df_overlap.sort_values('Avg IoU', ascending=False).head(10))"]}, {"cell_type": "code", "execution_count": null, "id": "15753f77", "metadata": {}, "outputs": [], "source": ["SAMPLE_NUM = 800 \n", "morph_data = []\n", "\n", "print(f\"Analyzing Shape Complexity & Edge Sharpness ({SAMPLE_NUM} samples)...\")\n", "\n", "# \ub79c\ub364 \uc0d8\ud50c\ub9c1\n", "import random\n", "sample_indices = random.sample(range(len(jsons)), min(len(jsons), SAMPLE_NUM))\n", "sample_jsons = [jsons[i] for i in sample_indices]\n", "\n", "for json_file in tqdm(sample_jsons):\n", "    json_path = os.path.join(LABEL_ROOT, json_file)\n", "    with open(json_path, 'r') as f:\n", "        data = json.load(f)\n", "        \n", "    png_filename = json_file.replace('.json', '.png')\n", "    img_path = os.path.join(IMAGE_ROOT, png_filename)\n", "    \n", "    # \uc774\ubbf8\uc9c0 \ub85c\ub4dc (Gradient \uacc4\uc0b0\uc6a9)\n", "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n", "    if img is None: continue\n", "    \n", "    # \uc774\ubbf8\uc9c0\uc758 Gradient Map \uacc4\uc0b0 (Sobel Filter)\n", "    # dx, dy\ub85c \uac00\ub85c/\uc138\ub85c \ubcc0\ud654\ub7c9\uc744 \uad6c\ud558\uace0 \ud569\uce69\ub2c8\ub2e4.\n", "    gX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n", "    gY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n", "    magnitude = np.sqrt(gX**2 + gY**2)\n", "    \n", "    annotations = data.get('annotations', [])\n", "    \n", "    for ann in annotations:\n", "        label = ann.get('label')\n", "        points = ann.get('points', [])\n", "        \n", "        if len(points) > 2:\n", "            pts = np.array(points, np.int32)\n", "            \n", "            # 1. Solidity \uacc4\uc0b0\n", "            area = cv2.contourArea(pts)\n", "            hull = cv2.convexHull(pts)\n", "            hull_area = cv2.contourArea(hull)\n", "            \n", "            solidity = 0\n", "            if hull_area > 0:\n", "                solidity = area / hull_area\n", "            \n", "            # 2. Edge Sharpness \uacc4\uc0b0\n", "            # \ud3f4\ub9ac\uace4\uc758 \uacbd\uacc4\uc120(Contour) \uc88c\ud45c\ub9cc \ub9c8\uc2a4\ud0b9\n", "            mask_contour = np.zeros_like(img, dtype=np.uint8)\n", "            cv2.drawContours(mask_contour, [pts], -1, 255, 1) # \ub450\uaed8 1\n", "            \n", "            # \uacbd\uacc4\uc120 \uc704\uce58\uc758 Gradient \uac12\ub4e4\ub9cc \ucd94\ucd9c\n", "            edge_gradients = magnitude[mask_contour == 255]\n", "            \n", "            if len(edge_gradients) > 0:\n", "                mean_sharpness = np.mean(edge_gradients)\n", "                \n", "                morph_data.append({\n", "                    'label': label,\n", "                    'solidity': solidity,\n", "                    'sharpness': mean_sharpness\n", "                })\n", "\n", "df_morph = pd.DataFrame(morph_data)\n", "\n", "# \uc2dc\uac01\ud654\n", "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n", "\n", "# (1) Solidity Plot\n", "# \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uc624\ubaa9\ud558\uace0 \ubcf5\uc7a1\ud55c \ubf08\n", "order_solidity = df_morph.groupby('label')['solidity'].median().sort_values().index\n", "sns.boxplot(data=df_morph, x='solidity', y='label', order=order_solidity, palette='coolwarm_r', ax=axes[0])\n", "axes[0].set_title(\"Shape Complexity (Solidity)\\nLower = More Concave/Complex Shape\")\n", "axes[0].set_xlabel(\"Solidity (Area / ConvexHull Area)\")\n", "axes[0].axvline(1.0, color='red', linestyle='--') # \uae30\uc900\uc120\n", "\n", "# (2) Edge Sharpness Plot\n", "# \uac12\uc774 \ub0ae\uc744\uc218\ub85d \uacbd\uacc4\uac00 \ud750\ub9bf\ud568\n", "order_sharpness = df_morph.groupby('label')['sharpness'].median().sort_values().index\n", "sns.boxplot(data=df_morph, x='sharpness', y='label', order=order_sharpness, palette='magma', ax=axes[1])\n", "axes[1].set_title(\"Edge Sharpness (Gradient Magnitude)\\nLower = Blurry/Fuzzy Edges\")\n", "axes[1].set_xlabel(\"Mean Gradient at Boundary\")\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "# \uc694\uc57d \ucd9c\ub825\n", "print(\"\\n=== Most Complex Shapes (Low Solidity) ===\")\n", "print(df_morph.groupby('label')['solidity'].mean().sort_values().head(5))\n", "\n", "print(\"\\n=== Most Blurry Edges (Low Sharpness) ===\")\n", "print(df_morph.groupby('label')['sharpness'].mean().sort_values().head(5))"]}, {"cell_type": "markdown", "id": "08c31c0a", "metadata": {}, "source": ["# META DATA"]}, {"cell_type": "code", "execution_count": null, "id": "bdbf597c", "metadata": {}, "outputs": [], "source": ["META_PATH = '/data/ephemeral/home/data/meta_data.xlsx'\n", "print(f\"Loading metadata from {META_PATH}...\")\n", "df_meta = pd.read_excel(META_PATH)"]}, {"cell_type": "code", "execution_count": null, "id": "4b469525", "metadata": {}, "outputs": [], "source": ["df_meta.head()"]}, {"cell_type": "code", "execution_count": null, "id": "290f7d27", "metadata": {}, "outputs": [], "source": ["len(df_meta) # train 400\uba85, test 150\uba85 -> 144\uba85"]}, {"cell_type": "code", "execution_count": null, "id": "23d68396", "metadata": {}, "outputs": [], "source": ["# (1) \uc131\ubcc4 \uceec\ub7fc: '\uc5ec', '\ub0a8' \ub4f1 \ud55c\uae00\ub9cc \uc3d9 \ubf51\uc544\ub0c5\ub2c8\ub2e4.\n", "# \ud2b9\uc218\ubb38\uc790, \uacf5\ubc31, \uc601\uc5b4, \uc22b\uc790 \ub4f1\uc740 \ubaa8\ub450 \ubb34\uc2dc\ub429\ub2c8\ub2e4.\n", "if '\uc131\ubcc4' in df_meta.columns:\n", "    # \ubb38\uc790\uc5f4\ub85c \ubcc0\ud658 \ud6c4, \ud55c\uae00(\uac00-\ud7a3)\uc5d0 \ud574\ub2f9\ud558\ub294 \uae00\uc790\ub9cc \ucd94\ucd9c\n", "    df_meta['\uc131\ubcc4'] = df_meta['\uc131\ubcc4'].astype(str).str.extract(r'([\uac00-\ud7a3]+)')[0]\n", "    \n", "    # \ud639\uc2dc \ubaa8\ub97c \uacf5\ubc31 \uc81c\uac70\n", "    df_meta['\uc131\ubcc4'] = df_meta['\uc131\ubcc4'].str.strip()\n", "\n", "# (2) ID \uceec\ub7fc \uc815\uc218 \ubcc0\ud658 (NaN \ucc98\ub9ac \ud3ec\ud568)\n", "if 'ID' in df_meta.columns:\n", "    # \uc22b\uc790\uac00 \uc544\ub2cc \uac12\uc774 \uc11e\uc5ec \uc788\uc744 \uc218 \uc788\uc73c\ubbc0\ub85c coerce\ub85c \ucc98\ub9ac\n", "    df_meta['ID'] = pd.to_numeric(df_meta['ID'], errors='coerce').fillna(0).astype(int)\n", "\n", "# (3) \ubd88\ud544\uc694\ud55c \uceec\ub7fc \uc81c\uac70\n", "df_meta = df_meta.loc[:, ~df_meta.columns.str.contains('^Unnamed')]\n", "\n", "print(\"=== Cleaned Metadata Check ===\")\n", "print(df_meta['\uc131\ubcc4'].unique())  \n", "display(df_meta.head())"]}, {"cell_type": "code", "execution_count": null, "id": "7c741d7e", "metadata": {}, "outputs": [], "source": ["\n", "print(f\"Searching for JSONs recursively in: {LABEL_ROOT}\")\n", "import glob\n", "# glob\uc744 \uc0ac\uc6a9\ud558\uc5ec \ubaa8\ub4e0 \ud558\uc704 \ud3f4\ub354\uc758 json \ud30c\uc77c\uc744 \ucc3e\uc2b5\ub2c8\ub2e4.\n", "# recursive=True\ub97c \uc4f0\uba74 \ud558\uc704 \ud3f4\ub354\uae4c\uc9c0 \ub2e4 \ub4a4\uc9d1\ub2c8\ub2e4.\n", "json_paths = glob.glob(os.path.join(LABEL_ROOT, '**', '*.json'), recursive=True)\n", "\n", "file_data = []\n", "\n", "print(f\"Found {len(json_paths)} JSON files in total.\")\n", "\n", "for json_path in json_paths:\n", "    # 1. \uc804\uccb4 \uacbd\ub85c\uc5d0\uc11c \ud30c\uc77c\uba85\uacfc \uc0c1\uc704 \ud3f4\ub354\uba85\uc744 \ubd84\ub9ac\n", "    folder_path = os.path.dirname(json_path)  # .../train_label/ID001\n", "    file_name = os.path.basename(json_path)   # 166113...json\n", "    \n", "    # 2. \uc0c1\uc704 \ud3f4\ub354\uba85 \ucd94\ucd9c (\uc608: 'ID001')\n", "    folder_name = os.path.basename(folder_path)\n", "    \n", "    # 3. \ud3f4\ub354\uba85\uc5d0\uc11c \uc22b\uc790 ID \ucd94\ucd9c\n", "    numbers = re.findall(r'\\d+', folder_name)\n", "    \n", "    if numbers:\n", "        # 'ID001' -> 1, '1' -> 1\n", "        folder_id = int(numbers[-1])\n", "        \n", "        file_data.append({\n", "            'file_name': file_name,     # \ub098\uc911\uc5d0 \uc774\ubbf8\uc9c0 \ub9e4\uce6d\uc6a9\n", "            'json_path': json_path,     # \ud30c\uc77c \uc5f4 \ub54c \uc0ac\uc6a9\n", "            'folder_name': folder_name, # \ud655\uc778\uc6a9\n", "            'ID': folder_id             # \uba54\ud0c0\ub370\uc774\ud130 \ub9e4\uce6d Key\n", "        })\n", "\n", "# \ub370\uc774\ud130\ud504\ub808\uc784 \uc0dd\uc131\n", "df_files = pd.DataFrame(file_data)\n", "\n", "print(\"\\n=== Extracted IDs from Folder Names ===\")\n", "if not df_files.empty:\n", "    print(df_files[['folder_name', 'ID', 'file_name']].head())\n", "else:\n", "    print(\"Error: \ud30c\uc77c\uc744 \ucc3e\uc9c0 \ubabb\ud588\uac70\ub098 \ud3f4\ub354\uba85\uc5d0\uc11c \uc22b\uc790\ub97c \ucd94\ucd9c\ud558\uc9c0 \ubabb\ud588\uc2b5\ub2c8\ub2e4.\")\n", "\n", "# ==========================================\n", "# 3. \ub370\uc774\ud130 \ubcd1\ud569 (Merge)\n", "# ==========================================\n", "if not df_files.empty:\n", "    df_merged = pd.merge(df_files, df_meta, on='ID', how='inner')\n", "    \n", "    print(f\"\\nSuccessfully Merged: {len(df_merged)} images.\")"]}, {"cell_type": "code", "execution_count": null, "id": "ccda46cc", "metadata": {}, "outputs": [], "source": ["# \uc2dc\uac01\ud654 \uc124\uc815\n", "sns.set_theme(style=\"whitegrid\")\n", "\n", "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n", "\n", "# 1. \uc131\ubcc4 \ubd84\ud3ec (Count Plot)\n", "ax1 = sns.countplot(data=df_merged, x='\uc131\ubcc4', palette='pastel', ax=axes[0, 0])\n", "axes[0, 0].set_title('Gender Distribution', fontsize=15)\n", "for container in ax1.containers:\n", "    ax1.bar_label(container, fontsize=12)\n", "\n", "# 2. \ub098\uc774 \ubd84\ud3ec (KDE Plot)\n", "# \uc5f0\ub839\ub300\uac00 \uc5b4\ub514\uc5d0 \uc9d1\uc911\ub418\uc5b4 \uc788\ub294\uc9c0 \ud655\uc778\n", "sns.histplot(data=df_merged, x='\ub098\uc774', kde=True, color='skyblue', ax=axes[0, 1])\n", "axes[0, 1].set_title('Age Distribution', fontsize=15)\n", "\n", "# 3. \uccb4\uc911 \ubd84\ud3ec\n", "sns.histplot(data=df_merged, x='\uccb4\uc911(\ubab8\ubb34\uac8c)', kde=True, color='lightgreen', ax=axes[1, 0])\n", "axes[1, 0].set_title('Weight Distribution', fontsize=15)\n", "\n", "# 4. \ud0a4 \ubd84\ud3ec\n", "sns.histplot(data=df_merged, x='\ud0a4(\uc2e0\uc7a5)', kde=True, color='salmon', ax=axes[1, 1])\n", "axes[1, 1].set_title('Height Distribution', fontsize=15)\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "# === [\ud1b5\uacc4 \uc694\uc57d \ucd9c\ub825] ===\n", "# \uc131\ubcc4\uc5d0 \ub530\ub978 \ud3c9\uade0 \ud0a4, \ubab8\ubb34\uac8c, \ub098\uc774 \ud655\uc778\n", "print(\"\\n=== Gender-based Statistics (Mean/Std) ===\")\n", "display(df_merged.groupby('\uc131\ubcc4')[['\ub098\uc774', '\ud0a4(\uc2e0\uc7a5)', '\uccb4\uc911(\ubab8\ubb34\uac8c)']].describe().T)"]}, {"cell_type": "code", "execution_count": null, "id": "97279458", "metadata": {}, "outputs": [], "source": ["df_merged.head().json_path"]}, {"cell_type": "code", "execution_count": null, "id": "2e7467b4", "metadata": {}, "outputs": [], "source": ["# ==========================================\n", "# 1. \ud2b9\uc9d5 \ucd94\ucd9c (Feature Extraction)\n", "# ==========================================\n", "# 20~30\ub300 \ub370\uc774\ud130\uc774\ubbc0\ub85c BMI(\ube44\ub9cc\ub3c4)\uac00 \ud654\uc9c8\uc5d0 \ubbf8\uce58\ub294 \uc601\ud5a5\uc774 \ub354 \uc911\uc694\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4.\n", "# BMI = \ubab8\ubb34\uac8c(kg) / (\ud0a4(m) ^ 2)\n", "df_merged['Height_m'] = df_merged['\ud0a4(\uc2e0\uc7a5)'] / 100\n", "df_merged['BMI'] = df_merged['\uccb4\uc911(\ubab8\ubb34\uac8c)'] / (df_merged['Height_m'] ** 2)\n", "\n", "image_stats = []\n", "\n", "print(\"Extracting features from 800 images based on Metadata...\")\n", "\n", "for idx, row in tqdm(df_merged.iterrows(), total=len(df_merged)):\n", "    # 1. JSON \uacbd\ub85c (\ubcd1\ud569\ub41c \ub370\uc774\ud130\ud504\ub808\uc784\uc5d0 \uc788\ub2e4\uace0 \uac00\uc815)\n", "    json_path = row['json_path']\n", "    \n", "    # 2. \uc774\ubbf8\uc9c0 \uacbd\ub85c \uc720\ucd94 (train_label -> train_input, .json -> .png)\n", "    # \uc2e4\uc81c \ud3f4\ub354 \uad6c\uc870\uc5d0 \ub9de\ucdb0\uc8fc\uc138\uc694. \ubcf4\ud1b5 label \ud3f4\ub354\uc640 input \ud3f4\ub354\uac00 \ud615\uc81c \uad00\uacc4\uc785\ub2c8\ub2e4.\n", "    img_path = json_path.replace('train_label', 'train_input').replace('.json', '.png')\n", "    \n", "    # (1) \ubf08 \uba74\uc801 \uacc4\uc0b0 (Scale \ud655\uc778\uc6a9)\n", "    total_area = 0\n", "    try:\n", "        with open(json_path, 'r') as f:\n", "            data = json.load(f)\n", "        for ann in data.get('annotations', []):\n", "            pts = ann.get('points', [])\n", "            if len(pts) > 2:\n", "                total_area += cv2.contourArea(np.array(pts, np.int32))\n", "    except Exception as e:\n", "        pass # \uc5d0\ub7ec \ubb34\uc2dc\n", "\n", "    # (2) \uc774\ubbf8\uc9c0 \ubc1d\uae30 \uacc4\uc0b0 (Contrast \ud655\uc778\uc6a9)\n", "    mean_intensity = 0\n", "    if os.path.exists(img_path):\n", "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n", "        if img is not None:\n", "            mean_intensity = np.mean(img)\n", "    \n", "    image_stats.append({\n", "        'ID': row['ID'],\n", "        'Total_Bone_Area': total_area,\n", "        'Mean_Intensity': mean_intensity\n", "    })\n", "\n", "# \ub370\uc774\ud130 \ud569\uce58\uae30\n", "df_stats = pd.DataFrame(image_stats)\n", "df_final = pd.merge(df_merged, df_stats, on='ID')\n", "\n", "# \uceec\ub7fc\uba85 \uc601\ubb38 \ubcc0\ud658 (\uc2dc\uac01\ud654 \uc624\ub958 \ubc29\uc9c0)\n", "df_final = df_final.rename(columns={'\uc131\ubcc4': 'Gender', '\ub098\uc774': 'Age', '\ud0a4(\uc2e0\uc7a5)': 'Height', '\uccb4\uc911(\ubab8\ubb34\uac8c)': 'Weight'})\n", "\n", "# ==========================================\n", "# 2. \uc2dc\uac01\ud654 (Insight \ub3c4\ucd9c)\n", "# ==========================================\n", "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n", "\n", "# [Graph 1] \uc131\ubcc4\uc5d0 \ub530\ub978 \ubf08 \ud06c\uae30 \ucc28\uc774 (Boxplot)\n", "# \ub0a8\ub140 \ud06c\uae30 \ucc28\uc774\uac00 \ud06c\ub2e4\uba74 -> RandomScale Augmentation \ud544\uc218\n", "sns.boxplot(data=df_final, x='Gender', y='Total_Bone_Area', palette='Set2', ax=axes[0])\n", "axes[0].set_title(\"1. Gender vs. Bone Area (Scale Diff)\", fontsize=15)\n", "\n", "# [Graph 2] \ud0a4\uc640 \ubf08 \ud06c\uae30\uc758 \uc0c1\uad00\uad00\uacc4 (Scatter)\n", "# \ud0a4\uac00 \ud074\uc218\ub85d \ubf08\uac00 \ud070\uac00? (\ub2f9\uc5f0\ud558\uaca0\uc9c0\ub9cc \ub208\uc73c\ub85c \ud655\uc778)\n", "sns.scatterplot(data=df_final, x='Height', y='Total_Bone_Area', hue='Gender', alpha=0.7, ax=axes[1])\n", "axes[1].set_title(\"2. Height vs. Bone Area\", fontsize=15)\n", "\n", "# [Graph 3] BMI\uc640 \uc774\ubbf8\uc9c0 \ubc1d\uae30 (Scatter + Reg)\n", "# \ub6b1\ub6b1\ud55c \uc0ac\ub78c(BMI High)\uc758 \uc0ac\uc9c4\uc774 \ub354 \uc5b4\ub450\uc6b4\uac00? -> Contrast Augmentation \ud544\uc218\n", "sns.regplot(data=df_final, x='BMI', y='Mean_Intensity', scatter_kws={'alpha':0.5}, line_kws={'color':'red'}, ax=axes[2])\n", "axes[2].set_title(\"3. BMI vs. Image Brightness (Soft Tissue)\", fontsize=15)\n", "\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "# ==========================================\n", "# 3. \uacb0\ub860 \ucd9c\ub825 (Action Item)\n", "# ==========================================\n", "male_mean = df_final[df_final['Gender']=='\ub0a8']['Total_Bone_Area'].mean()\n", "female_mean = df_final[df_final['Gender']=='\uc5ec']['Total_Bone_Area'].mean()\n", "scale_ratio = male_mean / female_mean\n", "\n", "print(f\"\\n=== [Conclusion for Modeling] ===\")\n", "print(f\"1. Scale Check: \ub0a8\uc131 \ubf08\uac00 \uc5ec\uc131\ubcf4\ub2e4 \uc57d {scale_ratio:.2f}\ubc30 \ud07d\ub2c8\ub2e4.\")\n", "if scale_ratio > 1.2:\n", "    print(\"   \u2705 ACTION: \uc131\ubcc4 \uac04 \ud06c\uae30 \ucc28\uc774\uac00 \ub69c\ub837\ud569\ub2c8\ub2e4. RandomScale(0.5 ~ 1.5) \uc99d\uac15\uc744 \uaf2d \uc801\uc6a9\ud558\uc138\uc694.\")\n", "else:\n", "    print(\"   ACTION: \ud06c\uae30 \ucc28\uc774\uac00 \ud06c\uc9c0 \uc54a\uc2b5\ub2c8\ub2e4. \uc57d\ud55c Scale \uc99d\uac15\ub9cc \uc788\uc5b4\ub3c4 \ub429\ub2c8\ub2e4.\")\n", "\n", "corr_bmi = df_final['BMI'].corr(df_final['Mean_Intensity'])\n", "print(f\"\\n2. Intensity Check: BMI\uc640 \ubc1d\uae30\uc758 \uc0c1\uad00\uacc4\uc218\ub294 {corr_bmi:.2f} \uc785\ub2c8\ub2e4.\")\n", "if corr_bmi < -0.3:\n", "    print(\"   \u2705 ACTION: \uccb4\uc911\uc774 \ub098\uac08\uc218\ub85d \uc0ac\uc9c4\uc774 \uc5b4\ub461\uc2b5\ub2c8\ub2e4. CLAHE\ub098 RandomBrightnessContrast\ub97c \uac15\ud558\uac8c \uc801\uc6a9\ud558\uc138\uc694.\")\n", "else:\n", "    print(\"   ACTION: BMI\uac00 \ud654\uc9c8\uc5d0 \ud070 \uc601\ud5a5\uc744 \uc8fc\uc9c0 \uc54a\ub294 \uae68\ub057\ud55c \ub370\uc774\ud130\uc14b\uc785\ub2c8\ub2e4.\")"]}], "metadata": {"kernelspec": {"display_name": "home", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.13"}}, "nbformat": 4, "nbformat_minor": 5}